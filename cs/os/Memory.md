# 목차

1. [메모리 계층](#메모리-계층)
    - [계층이 존재하는 이유](#계층이-존재하는-이유)
        - [더 빠른 접근과 처리속도가 증가](#더-빠른-접근과-처리속도가-증가)
        - [비용의 효율성](#비용의-효율성)
        - [자원의 효율적 사용](#자원의-효율적-사용)

2. [가상메모리와 스와핑, 페이지폴트 그리고 스레싱](#가상메모리와-스와핑-페이지폴트-그리고-스레싱)
    - [페이지 테이블](#페이지-테이블)
        - [프로세스A와 프로세스B가 실행 및 종료시의 메모리 할당 과정](#프로세스a와-프로세스b가-실행-및-종료시의-메모리-할당-과정)
    - [페이지폴트와 스와핑](#페이지폴트와-스와핑)
    - [페이지 폴트의 과정](#페이지-폴트의-과정)
    - [스레싱](#스레싱)
        - [하드웨어적 해결방법](#하드웨어적-해결방법)
        - [운영체제에서 해결하는 방법](#운영체제에서-해결하는-방법)
    - [가상 메모리의 필요성](#가상-메모리의-필요성)
        - [주기억 장치의 효율적 관리(스와핑)](#주기억-장치의-효율적-관리스와핑)
        - [메모리 관리의 단순화](#메모리-관리의-단순화)
        - [메모리 용량 및 안정성 보장](#메모리-용량-및-안정성-보장)

3. [페이지 히트와 페이지 미스](#페이지-히트와-페이지-미스)
    - [페이지 히트(Page Hit)](#페이지-히트page-hit)
    - [페이지 미스(Page Miss)](#페이지-미스page-miss)
    - [페이지 미스와 페이지 폴트](#페이지-미스와-페이지-폴트)

4. [페이지 교체 알고리즘 1. 오프라인 알고리즘(LFD)](#페이지-교체-알고리즘-1-오프라인-알고리즘lfd)

5. [페이지 교체 알고리즘 2. FIFO, LRU, NUR, LFU](#페이지-교체-알고리즘-2-fifo-lru-nur-lfu)
    - [FIFO(First In First Out)](#fifofirst-in-first-out)
    - [LRU(Least Recently Used)](#lruleast-recently-used)
    - [NUR(Not Used Recently) or NRU(Not Recently Used)](#nurnot-used-recently-or-nrunot-recently-used)
    - [LFU(Least Frequently Used)](#lfuleast-frequently-used)

# 메모리 계층

* 레지스터: CPU 내의 작은 메모리. 휘발성, 속도가 가장 빠름, 기억 용량이 가장 적음
* 캐시: CPU 내의 L1, L2 캐시를 지칭. 휩라성, 속도 빠름, 기억 용량이 적음
* 주기억장치: RAM. 휘발성, 속도 보통, 기억 용량 보통
* 보조기억장치: HDD, SSD. 비휘발성, 속도 낮음, 기억 용량 많음

## 계층이 존재하는 이유

### 더 빠른 접근과 처리속도가 증가

* 특정 데이터에 많이 접근하게 됨
* 좀 더 작은 캐시 메모리에 해당 데이터가 있다면 더 빠르게 해당 데이터에 접근이 가능함
* 그로 인해 처리 속도도 증가

### 비용의 효율성

* 캐시 메모리는 비싸고 램 등 아래로 갈수록 비용은 더 저렴
* 계층이 있고 캐싱 때문에 비용을 좀 더 효율적으로 사용 가능

### 자원의 효율적 사용

* 자주 접근하는 데이터는 빠른 메모리에, 덜 접근하는 데이터는 느린 메모리에 저장하여 자원을 효율적으로 사용할 수 있음
* 이렇게 하면 거의 접근하지 않은 데이터에 삐사고 빠른 메모리를 사용하지 않게 되어 자원을 낭비하지 않게 됨

# 가상메모리와 스와핑, 페이지폴트 그리고 스레싱

* 가상 메모리(virtual memory)는 OS에서 사용되는 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원(실제 주소, physical address)을 추상화하여 이를 사용하는 사용자들에게
  매우 큰 메모리로 보이게 만드는 것
* 가상 주소는 MMU와 페이지테이블에 의해 실제 주소로 변환됨
    * 페이지: **가상** 메모리를 사용하는 최소 크기 단위
    * 프레임: **실제** 디스크나 메모리를 사용하는 최소 크기 단위

## 페이지 테이블

* 가상 메모리는 가상 주소와 실제 주소가 매핑되어있는 페이지 테이블로 관리되며 이때 속도 향상을 위해 캐싱 계층은 TLB를 사용
* 가상 주소에서 바로 페이지 테이블을 가는 게 아니라 TLB에서 있는지를 확인하고 만약 없다면 페이지 테이블로 가서 실제 주소를 가져옴

### 프로세스A와 프로세스B가 실행 및 종료시의 메모리 할당 과정

1. 가상 메모리와 물리 메모리

* 각 프로세스는 자신만의 가상 주소 공간을 가지고 있음
* 가상 주소는 프로세스가 메모리에 접근할 때 사용하는 주소
    * 예를 들어, 프로세스 A와 B가 각각 0x0000과 0x1000의 가상 주소를 가지고 있다고 침
* 물리 메모리는 실제로 존재하는 RAM의 주소 공간
* 가상 주소는 실제로 물리 메모리의 주소와 직접적인 관계가 없음
* 이를 매핑해주는 페이지테이블이 있고 이걸 기반으로 CPU의 메모리 관리 유닛(MMU, Memory Management Unit)이 가상주소를 물리주소로 변환

2. 프로세스의 종료와 재실행

* 프로세스 A와 B가 종료되면, 그들의 가상 주소 공간과 페이지 테이블은 해제됨
    * A와 B가 다시 실행되면, 운영 체제는 새로운 가상 주소 공간을 할당함
* 하지만 가상 주소 공간이 이전과 동일하지 않을 수 있음
    * 운영체제는 가상 주소를 자유롭게 재사용할 수 있음
* 가상 주소가 동일하더라도 실제 물리 메모리 주소는 다를 수 있음
* 가상 주소는 항상 페이지 테이블을 통해 물리 주소로 변환됨

## 페이지폴트와 스와핑

* 가상 메모리는 작은 메모리를 매우 큰 메모리로 보이게끔 하는 것이기 때문에 참조하려는 메모리 영역이 실제 메모리에 없을 수 있음
    * 가상 메모리는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우가 있으며 이때 페이지 폴트가 발생
* 이때 메모리의 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 **마치 메모리처럼** 불러와 쓰는 것을 스와핑이라고 함

## 페이지 폴트의 과정

1. 명령어가 유효한 가상 주소에 접근했으나 해당 페이지가 물리 메모리에 없는 경우, CPU는 페이지 폴트를 감지하고 트랩을 발생시켜 운영체제에 알림
2. 운영체제는 해당 가상 주소가 유효한지 검사 후, 유효한 경우 디스크에서 필요한 페이지를 가져올 물리적 메모리 프레임을 찾음. 만약 빈 프레임이 있으며 그 프레임을 사용함
3. 모든 프레임이 사용중인 경우, 운영 체제는 페이지 교체 알고리즘(예: LRU, FIFO)에 따라 교체할 페이지를 결정하고, 해당 페이지를 디스크로 보냄(스와핑)
4. 디스크에서 새로운 페이지를 읽어와 빈 프레임에 로드
5. 페이지 테이블을 갱신하여 새로운 페이지의 물리적 위치를 반영
6. 해당 명령어를 다시 실행하여 중단된 작업 재개

## 스레싱

* 메모리의 페이지 폴트율이 높은 것을 의미
* 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생
* 페이지 폴트가 일어나면 CPU 이용률은 낮아짐
* CPU 이용률은 낮아지게 되면 운영체제는 CPU의 가용성을 높이기 위해 더 많은 프로세스를 메모리에 올리게 됨
* 이러한 악순환이 반복되어 스레싱이 일어남

### 하드웨어적 해결방법

* 메모리 늘리기
* HDD -> SSD로 교체

### 운영체제에서 해결하는 방법

* 작업 세트(working set)
    * 프로세스의 과거 사용이력을 기반으로 많이 사용하는 페이지 집합을 만들어 한꺼번에 미리 메모리에 로드하는 것
* PFF(Page Fault Frequency)
    * 페이지 폴트 빈도를 조절하는 방법
    * 상한선과 하한선을 만들고 상한선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄이는 방법

## 가상 메모리의 필요성

### 주기억 장치의 효율적 관리(스와핑)

* 하드디스크를 주기억장치에 대한 캐시로 설정하여, 당장 사용하는 영역만 유지하고 쓰지 않는 데이터는 하드디스크로 옮긴 뒤, 필요할 때만 램에 데이터를 불러와 올리고 다시 사용하지 않으면 하드디스크로 내림으로써 램을
  효과적으로 관리함

### 메모리 관리의 단순화

* 각 프로세스마다 가상메모리의 통일된 주소 공간을 배정할 수 있으므로 메모리 관리가 단순해짐
* **통일된 주소 공간**이란, 각 프로세스가 고유의 가상 메모리 주소 공간을 가진다는 것
* 이 주소 공간은 프로세스가 사용하는 동안 독립적이고 다른 프로세스와 겹치지 않음을 보장
* 각 프로세스는 자신만의 독립적인 가상 주소 공간을 가지므로, 실제 물리 메모리 주소와는 관계없이 같은 가상 주소를 사용할 수 있음
* 이를 통해 메모리 관리가 단순해짐

### 메모리 용량 및 안정성 보장

* 한정된 공간의 램이 아닌, 거의 무한한 가상메모리 공간을 배정함으로써 프로세스들끼리 메모리 침범이 일어날 여지를 크게 줄임

# 페이지 히트와 페이지 미스

## 페이지 히트(Page Hit)

* 프로세스가 요청한 페이지가 이미 메모리에 적재되어 있어 바로 접근할 수 있는 상황

## 페이지 미스(Page Miss)

* 프로세스가 요청한 해당 페이지가 메모리에 없는 상황

## 페이지 미스와 페이지 폴트

* 페이지 미스는 종종 페이지 폴트를 초래할 수 잇음
* 페이지 폴트는 요청된 페이지가 메모리에 없어 운영체제가 보조 저장 장치에서 해당 페이지를 메모리로 로드해야하는 상황
* 모든 페이지 폴트는 페이지 미스로 인해 발생하지만, 모든 페이지 미스가 페이지 폴트로 이어지는 것은 아님
* 다음의 경우 페이지 미스가 나지만 페이지 폴트로 이어지지 않음

1. 접근 권한 오류

* 해당 페이지에 대한 접근 권한이 없거나 잘못된 접근(예: 쓰기 금지된 페이지에 쓰기 시도)이 시도되었을 경우 운영체제는 이를 오류로 처리하고 해당 요청을 거부
* 이 경우 페이지 미스가 발생하지만 실제로 페이지를 메모리로 로드하지 않고, 접근 권한 위반 오류를 발생시키므로 페이지 폴트로 이어지지 않음

2. 성능최적화를 위해 미리 로드할 때의 페이지 미스

* 어떤 시스템 또는 운영체제에서 성능 최적화를 위해 펭지ㅣ를 실제로 사용하기 전에 미리 요청(프리페칭)하는 최적화 기법을 사용하기도 함
* 이때 실제 데이터 사용 전에 다른 데이터로 덮어쓰게 될 경우 페이지 미스는 발생하지만, 사용되지 않아 페이지 폴트로는 발전하지 않음

# 페이지 교체 알고리즘 1. 오프라인 알고리즘(LFD)

* 스와핑이 일어날 때 페이지 교체 알고리즘에 의해 페이지가 교체되게 되고 이 알고리즘들은 최대한 스와핑을 적게 하는 것을 목표로 함
* 오프라인 알고리즘(LFD, Longest Forward Distance)은 페이지 교체 알고리즘 중 가장 좋은 알고리즘이라고 일컫는 알고리즘임

1. 더이상 참조되지 않거나
2. 가장 늦게 다시 참조되는 페이지와 지금 요청된 페이지를 바꾸는 알고리즘

* 페이지 참조 순서: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3
* 메모리 최대 페이지 수: 3개
* 단계별 설명

1. 초기 요청: 1, 2, 3
    * 처음 세 페이지는 비어 있는 프레임에 하나씩 적재되며, 각각 페이지 폴트가 발생함
    * 현재 메모리: 1, 2, 3
2. 다음 요청: 4
    * 현재 메모리에 있는 페이지는 1, 2, 3
    * 각 페이지의 다음 참조는 다음과 같음
        * 1은 5번째 요청에서 다시 사용됨
        * 2는 6번째 요청에서 다시 사용됨
        * 3은 10번째 요청에서 다시 사용됨
    * 3번 페이지는 가장 늦게 사용되므로 교체하기에 최적의 선택
    * 교체: 3을 4로 교체
    * 현재 메모리: 1, 2, 4
3. 다음 요청: 1
    * 페이지 1은 이미 메모리에 있음
    * 현재 메모리: 1, 2, 4
4. 다음 요청: 2
    * 페이지 2 역시 이미 메모리에 있음
    * 현재 메모리: 1, 2, 4
5. 다음 요청: 5
    * 현재 메모리에 있는 페이지의 다음 참조는 다음과 같음
        * 1은 8번째 요청에서 다시 사용됨
        * 2는 9번째 요청에서 다시 사용됨
        * 4는 다시 사용되지 않음
    * 페이지 4는 다시 사용되지 않으므로 교체하기 최적의 선택
    * 교체: 4를 5로 교체
    * 현재 메모리: 1, 2, 5
6. 다음 요청: 1, 2, 3
    * 페이지 1과 페이지 2는 이미 메모리에 있으며 해당 요청에 따라 접근됨
    * 페이지 3 요청시 (1, 2, 5 중 아무거나 바꿀 수 있음)
    * 교체: 5를 3으로 교체
    * 현재 메모리: 1, 2, 3

* 이 알고리즘은 향후 요청을 모두 알고 있다는 가정 하에 **가장 효율적인 교체**를 함
* 이론적으로는 최적이지만 실제 시스템에서는 미래의 요청을 알 수 없기 때문에 직접 구현은 불가능
* 대신, LRU(Least Recently Used)나 LFU(Least Frequently Used) 같은 실현 가능한 대체 알고리즘이 사용됨
* 즉, 사용할 수 없는 알고리즘이지만 **다른 알고리즘과 성능 비교에 대한 상한선**을 제공

# 페이지 교체 알고리즘 2. FIFO, LRU, NUR, LFU

## FIFO(First In First Out)

* 가장 먼저 온 페이지부터 교체하는 방법

## LRU(Least Recently Used)

* 최근에 사용되지 않은 페이지를 교체하는 방법
* 즉, 참조가 오래된 페이지를 교체
* 이를 위해 각 페이지마다 최근 사용한 횟수를 나타내는 자료구조를 따로 만들어야 할 수도 있음

## NUR(Not Used Recently) or NRU(NOt Recently Used)

* LRU에서 발전한 알고리즘
* 일명 clock 알고리즘이라고 하며 먼저 0과 1을 가진 비트를 둠
* 1은 최근에 참조되었고 0은 참조되지 않음을 의미
* 만약 한 바퀴 도는 동안 사용되지 않으면 0이 됨
* 시계 방향으로 돌면서 0을 찾고, 0을 찾은 순가 ㄴ해당 페이지를 교체하고, 해당 부분을 1로 바꾸는 알고리즘

## LFU(Least Frequently Used)

* 가장 참조 횟수가 적은 페이지를 교체하는 알고리즘